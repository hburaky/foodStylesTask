{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96055514",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "debd07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d576504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files\n",
    "\n",
    "dataset_df = pd.read_csv('dataset.csv', low_memory=False)\n",
    "europe_df = pd.read_csv('europe_capitals_population_and_area.csv', sep= ';')\n",
    "paris_bounding_poligon_df = pd.read_json('paris_bounding_polygon.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6e56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find data type counts for each column and store them in a dict\n",
    "\n",
    "type_value_counts = {}\n",
    "for column in dataset_df.columns:\n",
    "    type_value_counts[column] = np.unique(dataset_df[[column]].applymap(type).astype(str).values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in type_value_counts.keys():\n",
    "    print(column)\n",
    "    for "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a3e5d",
   "metadata": {},
   "source": [
    "## 1. Identify the columns with mixed data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3135e754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed type columns are as follow:\n",
      "region\n",
      "province\n",
      "city\n",
      "claimed\n",
      "awards\n",
      "popularity_detailed\n",
      "popularity_generic\n",
      "top_tags\n",
      "price_level\n",
      "price_range\n",
      "meals\n",
      "cuisines\n",
      "special_diets\n",
      "features\n",
      "original_open_hours\n",
      "default_language\n",
      "keywords\n"
     ]
    }
   ],
   "source": [
    "#print mixed type columns\n",
    "\n",
    "print('mixed type columns are as follow:')\n",
    "for column in type_value_counts.keys():\n",
    "    if len(type_value_counts[column][1])>1:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b79897",
   "metadata": {},
   "source": [
    "## 2. For each column, count the number of rows per data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9783525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'restaurant_link': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'restaurant_name': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'original_location': (array([\"<class 'str'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'country': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'region': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([  50323, 1033074])),\n",
       " 'province': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([340632, 742765])),\n",
       " 'city': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([400685, 682712])),\n",
       " 'address': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'latitude': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'longitude': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'claimed': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([   1842, 1081555])),\n",
       " 'awards': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([820264, 263133])),\n",
       " 'popularity_detailed': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([ 94988, 988409])),\n",
       " 'popularity_generic': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([ 97792, 985605])),\n",
       " 'top_tags': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([110634, 972763])),\n",
       " 'price_level': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([277205, 806192])),\n",
       " 'price_range': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([779070, 304327])),\n",
       " 'meals': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([448050, 635347])),\n",
       " 'cuisines': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([169103, 914294])),\n",
       " 'special_diets': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([743141, 340256])),\n",
       " 'features': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([765990, 317407])),\n",
       " 'vegetarian_friendly': (array([\"<class 'str'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'vegan_options': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'gluten_free': (array([\"<class 'str'>\"], dtype=object), array([1083397])),\n",
       " 'original_open_hours': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([489565, 593832])),\n",
       " 'open_days_per_week': (array([\"<class 'float'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'open_hours_per_week': (array([\"<class 'float'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'working_shifts_per_week': (array([\"<class 'float'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'avg_rating': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'total_reviews_count': (array([\"<class 'float'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'default_language': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([ 95193, 988204])),\n",
       " 'reviews_count_in_default_language': (array([\"<class 'float'>\"], dtype=object),\n",
       "  array([1083397])),\n",
       " 'excellent': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'very_good': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'average': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'poor': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'terrible': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'food': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'service': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'value': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'atmosphere': (array([\"<class 'float'>\"], dtype=object), array([1083397])),\n",
       " 'keywords': (array([\"<class 'float'>\", \"<class 'str'>\"], dtype=object),\n",
       "  array([984199,  99198]))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37623f0a",
   "metadata": {},
   "source": [
    "## 3. Would removing missing values solve the mixed data type problem?\n",
    "\n",
    "### Answer: \n",
    "\n",
    "No. Because removing missing values is only possible by deleting rows which would result in loss of data. It is seen that the mixed data type problem is caused by string 'nan' values which should be NaN. Therefore, I mapped string 'nan's to numpy.nan values below which solved the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f13f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix mixed data type problem by mappint string 'nan' values to numpy.nan\n",
    "\n",
    "for column in type_value_counts.keys():\n",
    "    if len(type_value_counts[column]) > 1:\n",
    "        dataset_df[column] = dataset_df[column].map({'nan':np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3127889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find data type counts for each column and store them in a dict agagin\n",
    "\n",
    "type_value_counts = {}\n",
    "for column in dataset_df.columns:\n",
    "    type_value_counts[column] = np.unique(dataset_df[[column]].applymap(type).astype(str).values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4ef626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed type columns are as follow:\n"
     ]
    }
   ],
   "source": [
    "#print mixed type columns after mapping again\n",
    "\n",
    "print('mixed type columns are as follow:')\n",
    "for column in type_value_counts.keys():\n",
    "    if len(type_value_counts[column][1])>1:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa5f4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
